{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIC_Sprint22_リカレントニューラルネットワーク.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxI_09xWTNxN"
      },
      "source": [
        "# リカレントニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rJzEOq68bice"
      },
      "source": [
        "## 【事前準備】"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIbU_lsybicl",
        "outputId": "3e24e5b3-5202-42e3-9512-179730ba3692"
      },
      "source": [
        "# scikit-learnの「set_config(display=\"diagram\")」を使用するため、scikitlearnを最新verに更新\n",
        "# !pip install scikit-learn==0.23.2 --target drive/My\\ Drive/MyModule\n",
        "# !pip install scikit-learn==0.23.2\n",
        "# !pip install h5py==2.10\n",
        "# !pip install keras==2.3.1\n",
        "# !pip install keras-applications==1.0.7\n",
        "# !pip install tensorflow==1.14\n",
        "# !pip install -q -U albumentations   # データ拡張用ライブラリ\n",
        "!pip list\n",
        "## Google Drive上にインストールしたモジュールのインポート##\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/MyModule')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.1.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   1.12.3\n",
            "argon2-cffi                   21.1.0\n",
            "arviz                         0.11.2\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.2.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.6\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.2\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.5.30\n",
            "cffi                          1.14.6\n",
            "cftime                        1.5.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.4\n",
            "clang                         5.0\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorcet                      2.0.6\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.2.6\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.10.0\n",
            "cymem                         2.0.5\n",
            "Cython                        0.29.24\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.4\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.278\n",
            "easydict                      1.9\n",
            "ecos                          2.0.7.post1\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.0.0.2\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.6\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.0.12\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.4.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.34.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.5\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.53.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.1\n",
            "grpcio                        1.39.0\n",
            "gspread                       3.0.1\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.1.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.5\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.2.0\n",
            "imbalanced-learn              0.4.3\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.6.4\n",
            "importlib-resources           5.2.2\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2021.3.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.3\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.19\n",
            "jaxlib                        0.1.70+cuda110\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.0\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.0.1\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    2.6.0\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.7.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.5\n",
            "keras                         2.6.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.1\n",
            "korean-lunar-calendar         0.2.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.4\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-inline             0.1.2\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.8.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.2\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.9\n",
            "murmurhash                    1.0.5\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.4\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.1\n",
            "netCDF4                       1.5.7\n",
            "networkx                      2.6.2\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.7.3\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.4.3\n",
            "panel                         0.12.1\n",
            "param                         1.11.1\n",
            "parso                         0.8.2\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.1\n",
            "pep517                        0.11.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.4.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.5\n",
            "prettytable                   2.1.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.11.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "protobuf                      3.17.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.10.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.2\n",
            "pycparser                     2.20\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.2.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.2\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  2.5.6\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.1.1\n",
            "PyYAML                        3.13\n",
            "pyzmq                         22.2.1\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.1.1\n",
            "QtPy                          1.10.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.23.0\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.7.2\n",
            "scikit-image                  0.16.2\n",
            "scikit-learn                  0.22.2.post1\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           2.1.4\n",
            "seaborn                       0.11.1\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.7.1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.1.0\n",
            "snowballstemmer               2.1.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.5\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.22\n",
            "sqlparse                      0.4.1\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.6.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.6.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.6.0\n",
            "tensorflow-gcs-config         2.6.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-metadata           1.2.0\n",
            "tensorflow-probability        0.13.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.11.0\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "tifffile                      2021.8.30\n",
            "toml                          0.10.2\n",
            "tomli                         1.2.1\n",
            "toolz                         0.11.1\n",
            "torch                         1.9.0+cu102\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu102\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.0\n",
            "traitlets                     5.0.5\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.7.4.3\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.8.2\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.0\n",
            "widgetsnbextension            3.5.1\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.12.1\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   0.9.1\n",
            "zict                          2.0.0\n",
            "zipp                          3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_mFqIdjbico"
      },
      "source": [
        "## モジュールのインポート ##\n",
        "# 一般\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "import math\n",
        "import collections\n",
        "# データ分析\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import make_blobs\n",
        "# 決定木可視化のためのツール\n",
        "import graphviz\n",
        "import pydotplus\n",
        "# from IPython.display import Image\n",
        "# from sklearn.externals.six import StringIO\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "# Keras\n",
        "# from keras.datasets import mnist\n",
        "# SciPy\n",
        "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix, lil_matrix\n",
        "# 画像データ編集\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "# 自然言語処理\n",
        "from gensim.models import Word2Vec\n",
        "# その他\n",
        "from google.colab import drive #GoogleDriveモジュール\n",
        "# drive.mount('/content/drive') #GoogleDriveのマウント\n",
        "# os.chdir('/content/drive/My Drive/DIVE INTO CODE/Sprint/Sprint17/ObjectDetection-master')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGsUzyecWT-A"
      },
      "source": [
        "## 【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
        "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
        "\n",
        "\n",
        "フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n",
        "\n",
        "\n",
        "バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。\n",
        "\n",
        "\n",
        "$$\n",
        "a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + B\\\\\n",
        "h_t = tanh(a_t)\n",
        "$$\n",
        "\n",
        "\n",
        "a\n",
        "t\n",
        " : 時刻tの活性化関数を通す前の状態 (batch_size, n_nodes)\n",
        "\n",
        "\n",
        "h\n",
        "t\n",
        " : 時刻tの状態・出力 (batch_size, n_nodes)\n",
        "\n",
        "\n",
        "x\n",
        "t\n",
        " : 時刻tの入力 (batch_size, n_features)\n",
        "\n",
        "\n",
        "W\n",
        "x\n",
        " : 入力に対する重み (n_features, n_nodes)\n",
        "\n",
        "\n",
        "h\n",
        "t\n",
        "−\n",
        "1\n",
        " : 時刻t-1の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)\n",
        "\n",
        "\n",
        "W\n",
        "h\n",
        " : 状態に対する重み。 (n_nodes, n_nodes)\n",
        "\n",
        "\n",
        "B\n",
        " : バイアス項 (n_nodes,)\n",
        "\n",
        "初期状態 \n",
        "h\n",
        "0\n",
        " はすべて0とすることが多いですが、任意の値を与えることも可能です。\n",
        "\n",
        "\n",
        "上記の処理を系列数n_sequences回繰り返すことになります。RNN全体への入力 \n",
        "x\n",
        " は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していきます。\n",
        "\n",
        "\n",
        "分類問題であれば、それぞれの時刻のhに対して全結合層とソフトマックス関数（またはシグモイド関数）を使用します。タスクによっては最後の時刻のhだけを使用することもあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_zQOvkvqLhk"
      },
      "source": [
        "### ●ScratchSimpleRNNClassifierクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzC-oNjInMAl"
      },
      "source": [
        "class ScratchSimpleRNNClassifier():\n",
        "    \"\"\"\n",
        "    ディープニューラルネットワーク分類器\n",
        "    Parameters\n",
        "    ----------\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, layer_list, epoch, batch_size, early_stop=None, random_state=None, verbose=True):\n",
        "        self.verbose = verbose\n",
        "        self.flag = 0\n",
        "        self.layer_list = layer_list    # 各層のリスト（fitメソッドにて各層のクラスをインスタンス化）\n",
        "        self.layer_num = len(layer_list)   # 層の数\n",
        "        self.epoch = epoch  # エポック\n",
        "        self.batch_size = batch_size    # バッチサイズ\n",
        "        self.early_stop = early_stop    # 早期打ち切りのイテレーション回数\n",
        "        self.random_state = random_state\n",
        "        np.random.seed(random_state)   #乱数シードを設定\n",
        "        self.enc = OneHotEncoder(handle_unknown='ignore', sparse=False)   # OneHotエンコーダ\n",
        "        self.loss = np.array([])    # 損失関数（学習データ）\n",
        "        self.val_loss = np.array([])    # 損失関数（検証データ）\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]    # サンプル数\n",
        "        counter = 0   # 早期終了用のカウンタ\n",
        "\n",
        "        # 学習に使用する各種変数を初期化\n",
        "        self._init_variables(X)\n",
        "\n",
        "        # 学習データの目的変数をOneHotエンコーディング\n",
        "        Y = self.enc.fit_transform(y[:, np.newaxis])\n",
        "        # ミニバッチ学習用のクラス作成\n",
        "        get_mini_batch = GetMiniBatch(X, Y, batch_size=self.batch_size, seed=self.random_state)\n",
        "\n",
        "        # 検証データも与えられている場合\n",
        "        if ((X_val is not None) and (y_val is not None)):\n",
        "            # OneHotエンコーディング\n",
        "            Y_val = enc.transform(y_val[:, np.newaxis])\n",
        "\n",
        "         \n",
        "        # エポックの回数ループ\n",
        "        for j in range(self.epoch):\n",
        "            if self.verbose:   print(\"■エポック{}回目\".format(j))   # デバッグ情報出力\n",
        "            get_mini_batch.__iter__()  # ミニバッチのイテレータをリセット\n",
        "\n",
        "            # 全バッチデータを学習完了するまでループ（＝イテレーションの回数）\n",
        "            for i, (X_mini, Y_mini) in enumerate(get_mini_batch):\n",
        "                if self.verbose:   print(\"■イテレーション{}回目\".format(i))   # デバッグ情報出力\n",
        "                # 入力層から出力層までの順伝播処理および逆伝播処理\n",
        "                Zout = self._exec_propagation(X_mini, Y_mini)\n",
        "                # 損失関数\n",
        "                self.loss = np.append(self.loss, self._calcurate_loss(Y_mini, Zout))\n",
        "\n",
        "                # 検証データも与えられている場合は検証データに対しても同様の処理を行う\n",
        "                if ((X_val is not None) and (y_val is not None)):\n",
        "                    # 入力層から出力層までの順伝播処理\n",
        "                    Zout_val = self._exec_forward_propagation(X_val)\n",
        "                    # 損失関数\n",
        "                    self.val_loss = np.append(self.val_loss, self._calcurate_loss(Y_val, Zout_val))\n",
        "\n",
        "                # 早期終了のイテレーション回数が設定されている場合、カウンタをインクリメント\n",
        "                if (self.early_stop is not None):\n",
        "                    counter += 1\n",
        "                    # カウンタが設定値に到達したら学習を強制終了\n",
        "                    if (counter >= self.early_stop):\n",
        "                        break\n",
        "\n",
        "            # カウンタが設定値に到達したら学習を強制終了\n",
        "            if (self.early_stop is not None):\n",
        "                if (counter >= self.early_stop):\n",
        "                    break\n",
        "\n",
        "        if self.verbose:   print(\"■学習完了\")\n",
        "        return\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        DNN分類器を使い推定する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            特徴量データ\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred    次の形のndarray, shape (n_samples, )\n",
        "            ラベルの推定値\n",
        "        \"\"\"\n",
        "        Z = self._exec_forward_propagation(X)   # 順伝播処理\n",
        "        y_pred = np.argmax(Z, axis=1)   \n",
        "        return  y_pred\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        DNN分類器を使い推定値の確率を出力する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            特徴量データ\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred_proba    次の形のndarray, shape (n_samples, n_output)\n",
        "            ラベルの各クラスごとの確率の推定値\n",
        "        \"\"\"\n",
        "        y_pred_proba = self._exec_forward_propagation(X)   # 順伝播処理\n",
        "        return  y_pred_proba\n",
        "\n",
        "    def plot_learning_curve(self):\n",
        "        \"\"\"\n",
        "        学習曲線をプロットする関数\n",
        "        Parameters\n",
        "        ----------\n",
        "        None\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "        # 学習データと検証データのそれぞれの損失関数の値をグラフに描画\n",
        "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
        "        ax.set_title(\"Learning Curve\")\n",
        "        ax.set_xlabel(\"Iteration Number\")\n",
        "        ax.set_ylabel(\"Loss\")\n",
        "        ax.plot(self.loss, color = \"blue\", label=\"train\")\n",
        "        ax.plot(self.val_loss, color = \"red\", label=\"validation\")\n",
        "        ax.legend(loc='best') # 凡例を最適位置に表示\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    def _init_variables(self, X):\n",
        "        \"\"\"\n",
        "        学習に使用する各種変数を初期化する\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            特徴量データ\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■_init_variablesメソッド開始\")  # デバッグ情報出力\n",
        "        n_samples = X.shape[0]    # サンプル数\n",
        "\n",
        "        self.iter = int(n_samples / self.batch_size)   # イテレーション数\n",
        "        self.layer = [LayerClass(**keywards) for LayerClass, keywards in self.layer_list]    # 各層のインスタンスのリスト\n",
        "\n",
        "        if self.verbose:   print(\"■_init_variablesメソッド終了\")  # デバッグ情報出力\n",
        "        return\n",
        "\n",
        "    def _exec_propagation(self, X, Y):\n",
        "        \"\"\"\n",
        "        順伝播処理および逆伝播処理を実行する（学習データ用）\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_sequence, n_features)\n",
        "            特徴量データ\n",
        "        Y : 次の形のndarray, shape (batch_size, n_output)\n",
        "            訓練データの正解値(OneHotEncoding済み)\n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        # デバッグ情報出力\n",
        "        if self.verbose:   print(\"■_exec_propagationメソッド開始\")\n",
        "\n",
        "        batch_size = X.shape[0]\n",
        "        n_output = X.shape[0]\n",
        "\n",
        "        # 各レイヤの出力値の初期化\n",
        "        Z1 = np.zeros((batch_size, self.layer[0].n_nodes_current))\n",
        "\n",
        "        ## 順伝播処理 ##\n",
        "        # Xを(batch_size, n_sequence, n_features)⇒(n_sequence, batch_size, n_features)に軸変換\n",
        "        X_transposed = np.transpose(X, (1, 0, 2))\n",
        "        if self.verbose:  print(\"X_transposed.shape: {}\".format(X_transposed.shape))    # デバッグ情報出力\n",
        "\n",
        "        # 各時刻のXを順番に順伝播\n",
        "        for X_snapshot in X_transposed:\n",
        "            A1 = self.layer[0].forward(X_snapshot, Zout)   # SimpleRNNLayer\n",
        "            Zout = self.layer[1].forward(A1)               # SigmoidLayer or TanhLayer or ReLU\n",
        "        \n",
        "        ## 逆伝播処理 ##\n",
        "        # [TBD]\n",
        "\n",
        "        if self.verbose:   print(\"■_exec_propagationメソッド終了\")    # デバッグ情報出力\n",
        "        return  Zout\n",
        "\n",
        "    def _exec_forward_propagation(self, X):\n",
        "        \"\"\"\n",
        "        入力層から出力層まで順伝播処理を実行する（検証データ用）\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_features)\n",
        "            特徴量データ\n",
        "        Returns\n",
        "        -------\n",
        "        Zout : 次の形のndarray, shape (batch_size, n_output)\n",
        "            出力層の出力\n",
        "        \"\"\"\n",
        "        # デバッグ情報出力\n",
        "        if self.verbose:   print(\"■_exec_forward_propagationメソッド開始\")\n",
        "\n",
        "        batch_size = X.shape[0]\n",
        "        n_output = X.shape[0]\n",
        "\n",
        "        # 各レイヤの出力値の初期化\n",
        "        Z1 = np.zeros((batch_size, self.layer[0].n_nodes_current))\n",
        "\n",
        "        ## 順伝播処理 ##\n",
        "        # Xを(batch_size, n_sequence, n_features)⇒(n_sequence, batch_size, n_features)に軸変換\n",
        "        X_transposed = np.transpose(X, (1, 0, 2))\n",
        "        if self.verbose:  print(\"X_transposed.shape: {}\".format(X_transposed.shape))    # デバッグ情報出力\n",
        "\n",
        "        # 各時刻のXを順番に順伝播\n",
        "        for X_snapshot in X_transposed:\n",
        "            A1 = self.layer[0].forward(X_snapshot, Z1)   # SimpleRNNLayer\n",
        "            Z1 = self.layer[1].forward(A1)               # SigmoidLayer or TanhLayer or ReLU\n",
        "\n",
        "        Zout = Z1\n",
        "\n",
        "        if self.verbose:   print(\"■_exec_forward_propagationメソッド終了\")    # デバッグ情報出力\n",
        "        return Zout\n",
        "\n",
        "    def _calcurate_loss(self, Y, Z):\n",
        "        \"\"\"\n",
        "        損失関数（交差エントロピー誤差: L = -1/(batch_size)*ΣΣy_jk*log(Z_jk)）の計算\n",
        "        Parameters\n",
        "        ----------\n",
        "        Y : 次の形のndarray, shape (batch_size, n_output)\n",
        "            正解ラベルデータ（OneHotEncoding済み）\n",
        "        Z : 次の形のndarray, shape (batch_size, n_output)\n",
        "            出力層での出力値\n",
        "        Returns\n",
        "        ----------\n",
        "        loss : numpy.float\n",
        "          損失関数(交差エントロピー誤差)\n",
        "        \"\"\"\n",
        "        batch_size = Y.shape[0]\n",
        "        n_output = Y.shape[1]\n",
        "        sigma = 0\n",
        "\n",
        "        sigma = (Y * np.log(Z)).sum()   # ΣΣy_jk*log(Z_jk)の計算\n",
        "        loss = - (1 / batch_size) * sigma\n",
        "        return  loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih8UD1r6PjWc"
      },
      "source": [
        "### ●SimpleRNNLayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV0zIeINPpA3"
      },
      "source": [
        "class SimpleRNNLayer:\n",
        "    \"\"\"\n",
        "    今タイムステップの入力値と前タイムステップの出力値の両方を入力とする、RNNレイヤー\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes_prev : int\n",
        "      前の層のノード数\n",
        "    n_nodes_current : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes_prev, n_nodes_current, initializer, optimizer):\n",
        "        self.n_nodes_prev = n_nodes_prev\n",
        "        self.n_nodes_current = n_nodes_current\n",
        "        self.initializer = initializer  # WとBの初期化に使用\n",
        "        self.optimizer = optimizer  # WとBの更新時に使用\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "        # 重み ※FC層と異なり、RNN層の重みWには前タイムステップの出力値に対する重みも含まれる\n",
        "        self.W =self.initializer.init_W((n_nodes_prev + n_nodes_current), n_nodes_current) \n",
        "        # バイアス\n",
        "        self.B =self.initializer.init_B(n_nodes_prev, n_nodes_current)\n",
        "        self.W_log = np.array([])\n",
        "        self.B_log = np.array([])\n",
        "        self.flag = 1\n",
        "\n",
        "    def forward(self, Zprev, Alast):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        Zprev : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "            入力\n",
        "        Zlast : 次の形のndarray, shape (batch_size, n_nodes_current)\n",
        "            当層での前回の出力A\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_current)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        # A = (Zprev @ self.W) + self.B.reshape(1, self.B.shape[0])\n",
        "        ZA = np.concatenate([Zprev, Alast], axis=1) # 前層からの入力Zprevと前回の出力Alastを横方向に結合\n",
        "        A = (ZA @ self.W) + self.B.reshape(1, self.B.shape[0])\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA, Zprev):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes_current)\n",
        "            後ろから流れてきた勾配\n",
        "        Zprev : 次の形のndarray, shape (batch_size, prev_node_num)\n",
        "            前層の出力Z（当層が第2層の場合、Zprev=Z1）\n",
        "        Returns\n",
        "        ----------\n",
        "        dZprev : 次の形のndarray, shape (batch_size, prev_node_num)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        dW = Zprev.T @ dA\n",
        "        dB = dA.sum(axis=0)\n",
        "        dZprev = dA @ self.W.T\n",
        "\n",
        "        # 更新\n",
        "        self.W = self.optimizer.update(self.W, dW, \"W\")\n",
        "        self.B = self.optimizer.update(self.B, dB, \"B\")\n",
        "\n",
        "        # パラメータの一部のみログに記録\n",
        "        if (self.flag == 1):\n",
        "            self.W_log = self.W[0, :2].reshape(1, -1)\n",
        "            self.B_log = self.B[:2].reshape(1, -1)\n",
        "            self.flag = 0\n",
        "        else:\n",
        "            self.W_log = np.append(self.W_log, self.W[0, :2].reshape(1, -1), axis=0)\n",
        "            self.B_log = np.append(self.B_log, self.B[:2].reshape(1, -1), axis=0)\n",
        "\n",
        "        return dZprev"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTzqAY6fi6PO"
      },
      "source": [
        "### ●FullyConnectedLayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPnAus02i4Gg"
      },
      "source": [
        "class FullyConnectedLayer:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes_prevからn_nodes_currentへの全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes_prev : int\n",
        "      前の層のノード数\n",
        "    n_nodes_current : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes_prev, n_nodes_current, initializer, optimizer):\n",
        "        self.n_nodes_prev = n_nodes_prev\n",
        "        self.n_nodes_current = n_nodes_current\n",
        "        self.initializer = initializer  # WとBの初期化に使用\n",
        "        self.optimizer = optimizer  # WとBの更新時に使用\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "        self.W =self.initializer.init_W(n_nodes_prev, n_nodes_current) # 重み\n",
        "        self.B =self.initializer.init_B(n_nodes_prev, n_nodes_current) # バイアス\n",
        "        self.W_log = np.array([])\n",
        "        self.B_log = np.array([])\n",
        "        self.flag = 1\n",
        "\n",
        "    def forward(self, Zprev):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        Zprev : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_current)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        A = (Zprev @ self.W) + self.B.reshape(1, self.B.shape[0])\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA, Zprev):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes_current)\n",
        "            後ろから流れてきた勾配\n",
        "        Zprev : 次の形のndarray, shape (batch_size, prev_node_num)\n",
        "            前層の出力Z（当層が第2層の場合、Zprev=Z1）\n",
        "        Returns\n",
        "        ----------\n",
        "        dZprev : 次の形のndarray, shape (batch_size, prev_node_num)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        dW = Zprev.T @ dA\n",
        "        dB = dA.sum(axis=0)\n",
        "        dZprev = dA @ self.W.T\n",
        "\n",
        "        # 更新\n",
        "        self.W = self.optimizer.update(self.W, dW, \"W\")\n",
        "        self.B = self.optimizer.update(self.B, dB, \"B\")\n",
        "\n",
        "        # パラメータの一部のみログに記録\n",
        "        if (self.flag == 1):\n",
        "            self.W_log = self.W[0, :2].reshape(1, -1)\n",
        "            self.B_log = self.B[:2].reshape(1, -1)\n",
        "            self.flag = 0\n",
        "        else:\n",
        "            self.W_log = np.append(self.W_log, self.W[0, :2].reshape(1, -1), axis=0)\n",
        "            self.B_log = np.append(self.B_log, self.B[:2].reshape(1, -1), axis=0)\n",
        "\n",
        "        return dZprev"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2QjT4sylZ6j"
      },
      "source": [
        "### ●SigmoidLayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvqWlReElZ6t"
      },
      "source": [
        "class SigmoidLayer:\n",
        "    \"\"\"\n",
        "    シグモイド関数の層\n",
        "    Parameters\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose):\n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播処理\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■シグモイド関数（順伝播）実行\")   # デバッグ情報出力\n",
        "        Z = self._sigmoid_func(A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, A, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播処理\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■シグモイド関数（逆伝播）実行\")   # デバッグ情報出力\n",
        "        dA = dZ * (1 - self._sigmoid_func(A)) * self._sigmoid_func(A)\n",
        "        return dA\n",
        "\n",
        "    def _sigmoid_func(self, A):\n",
        "        \"\"\"\n",
        "        シグモイド関数(1/(1+exp(-A)))の演算処理\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        Z = 1/(1 + np.exp(-A))\n",
        "        return Z"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSd3I11YZzqo"
      },
      "source": [
        "### ●TanhLayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUfGrEAYZzq0"
      },
      "source": [
        "class TanhLayer:\n",
        "    \"\"\"\n",
        "    ハイパボリックタンジェント関数の層\n",
        "    Parameters\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose):\n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播処理((exp(A)-exp(-A))/(exp(A)+exp(-A)))\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ハイパボリックtan関数（順伝播）実行\")   # デバッグ情報出力\n",
        "        Z = self._tanh_func(A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, A, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播処理\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ハイパボリックtan関数（逆伝播）実行\")   # デバッグ情報出力\n",
        "        dA = dZ * (1 - self._tanh_func(A)* self._tanh_func(A)) \n",
        "        return dA\n",
        "\n",
        "    def _tanh_func(self, A):\n",
        "        \"\"\"\n",
        "        ハイパボリックtan関数((exp(A)-exp(-A))/(exp(A)+exp(-A)))の演算処理\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        Z = (np.exp(A) - np.exp(-A)) / (np.exp(A) + np.exp(-A))\n",
        "        return Z"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3xkinvOvzDd"
      },
      "source": [
        "### ●ReLULayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4mkxGf3vzDi"
      },
      "source": [
        "class ReLULayer:\n",
        "    \"\"\"\n",
        "    ReLU関数の層\n",
        "    Parameters\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose):\n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播処理\n",
        "            # df(x)/dx = { x (x > 0)\n",
        "            #            { 0 (x <= 0)\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ReLU関数（順伝播）実行\")   # デバッグ情報出力\n",
        "        # Z = np.where(A > 0, A, 0)\n",
        "        self.mask = (A <= 0)\n",
        "        Z = A.copy()\n",
        "        Z[self.mask] = 0\n",
        "        return Z\n",
        "\n",
        "    def backward(self, A, dZ):\n",
        "        \"\"\"\n",
        "        逆伝播処理\n",
        "            # df(x)/dx = { 1 (x > 0)\n",
        "            #            { 0 (x <= 0)\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ReLU関数（逆伝播）実行\")   # デバッグ情報出力\n",
        "        # dA = np.where(A > 0, 1, 0)\n",
        "        dZ[self.mask] = 0\n",
        "        dA = dZ\n",
        "        return dA"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNPnJ7tnSatq"
      },
      "source": [
        "### ●SoftmaxLayerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjF0MW_NSat1"
      },
      "source": [
        "class SoftmaxLayer:\n",
        "    \"\"\"\n",
        "    ソフトマックス関数の層\n",
        "    Parameters\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose):\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        順伝播処理(Z_k = (exp(A_k)/(Σexp(A_i))\n",
        "        Parameters\n",
        "        ----------\n",
        "        Returns\n",
        "        ----------\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ソフトマックス関数実行\")   # デバッグ情報出力\n",
        "        batch_size = A.shape[0]   # バッチサイズ\n",
        "        n_nodes_current = A.shape[1]    # 当層のノード数（＝目的変数のクラス数）\n",
        "        Z = np.zeros((batch_size, n_nodes_current))\n",
        "\n",
        "        sigma = np.exp(A).sum(axis=1)   # \"Σexp(A_i) (i=1～10)\"の部分の計算\n",
        "        Z = (np.exp(A)) / sigma.reshape(-1, 1)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, Z, Y):\n",
        "        \"\"\"\n",
        "        逆伝播処理\n",
        "        Parameters\n",
        "        ----------\n",
        "          Z : 順伝播処理の出力\n",
        "          Y : 目的変数（OneHotEncoding済み）\n",
        "        Returns\n",
        "        ----------\n",
        "          dA\n",
        "        \"\"\"\n",
        "        if self.verbose:   print(\"■ソフトマックス関数（逆伝播）実行\")   # デバッグ情報出力\n",
        "        batch_size = Z.shape[0]   # バッチサイズ\n",
        "        dA = (1 / batch_size) * (Z - Y)\n",
        "        return dA"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiTqgS8da4P7"
      },
      "source": [
        "### ●SimpleInitializerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE9WB60ja6fF"
      },
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    ガウス分布によるシンプルな初期化\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def init_W(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = self.sigma * np.random.randn(n_nodes_prev, n_nodes_current)\n",
        "        \n",
        "        return W\n",
        "\n",
        "    def init_B(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = self.sigma * np.random.randn(n_nodes_current)\n",
        "        return B"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuHHC8G_zG1E"
      },
      "source": [
        "### ●XavierInitializerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyYYYBRkzG1P"
      },
      "source": [
        "class XavierInitializer:\n",
        "    \"\"\"\n",
        "    「Xavierの初期値」による初期化（シグモイド関数・ハイパボリックタンジェント関数の層で使用）\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def init_W(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = (1 / np.sqrt(n_nodes_prev)) * np.random.randn(n_nodes_prev, n_nodes_current)\n",
        "        return W\n",
        "\n",
        "    def init_B(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = (1 / np.sqrt(n_nodes_prev)) * np.random.randn(n_nodes_current)\n",
        "        return B"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh7arQxs0l_6"
      },
      "source": [
        "### ●HeInitializerクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnTuQHVI0l_9"
      },
      "source": [
        "class HeInitializer:\n",
        "    \"\"\"\n",
        "    「Heの初期値」による初期化（ReLU関数の層で使用）\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      ガウス分布の標準偏差\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def init_W(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = (np.sqrt(2 / n_nodes_prev)) * np.random.randn(n_nodes_prev, n_nodes_current)\n",
        "        return W\n",
        "        \n",
        "    def init_B(self, n_nodes_prev, n_nodes_current):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes_prev : int\n",
        "          前の層のノード数\n",
        "        n_nodes_current : int\n",
        "          後の層のノード数\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = (np.sqrt(2 / n_nodes_prev)) * np.random.randn(n_nodes_current)\n",
        "        return B"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9q8dK-bBPN"
      },
      "source": [
        "### ●SGDクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MTUC21abD2o"
      },
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    確率的勾配降下法\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : 学習率\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, param, grad, param_name):\n",
        "        \"\"\"\n",
        "        ある層の重みやバイアスの更新\n",
        "        Parameters\n",
        "        ----------\n",
        "        param : 更新前の層のインスタンス (shape: (n_nodes_prev, n_nodes_current))\n",
        "        grad : 勾配 (shape: (n_nodes_prev, n_nodes_current))\n",
        "        param_name : パラメータの名称   ※SGDでは未使用\n",
        "        \"\"\"\n",
        "        ret_param = param - self.lr * grad\n",
        "        return ret_param"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK9q_CO52OUL"
      },
      "source": [
        "### ●AdaGradクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgNsGdt22OUX"
      },
      "source": [
        "class AdaGrad:\n",
        "    \"\"\"\n",
        "    AdaGradによるパラメータの更新\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : 学習率\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.flag = 1\n",
        "        self.H = {}\n",
        "\n",
        "    def update(self, param, grad, param_name):\n",
        "        \"\"\"\n",
        "        ある層の重みやバイアスの更新\n",
        "        Parameters\n",
        "        ----------\n",
        "        param : 更新前の層のインスタンス (shape: (n_nodes_prev, n_nodes_current))\n",
        "        grad : 勾配 (shape: (n_nodes_prev, n_nodes_current))\n",
        "        param_name : パラメータの名称\n",
        "        \"\"\"\n",
        "        # 初回のみ\n",
        "        if (param_name not in self.H):\n",
        "            dic = {param_name : grad * grad + 1e-7}   # 0割防止のため1e-7を加算\n",
        "        # 2回目以降\n",
        "        else:\n",
        "            dic = {param_name : (self.H[param_name] + grad * grad)}   # 前回までのself.H[param_name]にgrad * gradを加算\n",
        "        self.H.update(dic)    # self.H[param_name]の値を更新\n",
        "        ret_param = param -  self.lr * (1 / np.sqrt(self.H[param_name])) *grad\n",
        "        # print(\"AdaGradの勾配の2乗和:\")\n",
        "        # print((1 / np.sqrt(self.H[param_name]))[0])\n",
        "        return ret_param"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv6yuMxirD-d"
      },
      "source": [
        "### ●GetMiniBatchクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUZTe8fBrFVp"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "        self._counter = 0\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "            # print(\"Warning: バッチデータが最後に達しました！　データの先頭に戻ります!!!(self._counter = {})\".format(self._counter))\n",
        "            # self._counter = 0\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "\n",
        "# ## ミニバッチデータを取得するサンプルコード ##\n",
        "# get_mini_batch = GetMiniBatch(X_train1, y_train1, batch_size=20, seed=0)\n",
        "# # get_mini_batch = GetMiniBatch(X_test1, y_test1, batch_size=20, seed=0)\n",
        "# print(\"len(get_mini_batch):\")\n",
        "# print(len(get_mini_batch)) # 2400\n",
        "# print(\"get_mini_batch[5]:\")\n",
        "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
        "# # for i, (mini_X_train, mini_y_train) in enumerate(get_mini_batch):\n",
        "# #     # このfor文内でミニバッチが使える\n",
        "# #     # print(\"■{}番目のmini_X_train\".format(i))\n",
        "# #     # print(mini_X_train[0])\n",
        "# #     pass\n",
        "\n",
        "# get_mini_batch.__iter__()\n",
        "# for i in range(2):\n",
        "#     mini_X_train, mini_y_train = get_mini_batch.__next__()\n",
        "#     print(mini_X_train, mini_y_train)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86JK6LX-WsTh"
      },
      "source": [
        "## 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
        "小さな配列でフォワードプロパゲーションを考えてみます。\n",
        "\n",
        "\n",
        "入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n",
        "\n",
        "\n",
        "ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DGgt48kTHMF",
        "outputId": "eb31edbe-9033-4406-83d3-847063c8bd8f"
      },
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_feature)\n",
        "print(x.shape)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "print(w_x.shape)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "print(w_h.shape)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 3, 2)\n",
            "(2, 4)\n",
            "(4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftjVOqjoW7jB"
      },
      "source": [
        "フォワードプロパゲーションの出力が次のようになることを作成したコードで確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bSgAy7HW2XU"
      },
      "source": [
        "h = np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]]) # (batch_size, n_nodes)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWVPD3EDXdRD"
      },
      "source": [
        "### 【問題2 解答】↓↓↓"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEKph-v1XcGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab35748-7e80-423b-8091-cba3a7986162"
      },
      "source": [
        "# %%time\n",
        "epoch = 1   # エポック\n",
        "lr=1    # 学習率\n",
        "# batch_size = 20   # バッチサイズ\n",
        "early_stop = None   # 早期終了する場合のイテレーション回数（デバッグ用）\n",
        "verbose = False  # デバッグ情報出力のスイッチ\n",
        "\n",
        "             # LayerClass,          {keywards}\n",
        "layer_list = [(SimpleRNNLayer,      {\"n_nodes_prev\":n_features, \"n_nodes_current\":n_nodes, \"initializer\":SimpleInitializer(sigma=0.01), \"optimizer\":SGD(lr)}),\n",
        "              (TanhLayer,           {\"verbose\":verbose})]\n",
        "\n",
        "# ScratchSimpleRNNClassifierをインスタンス化\n",
        "clf = ScratchSimpleRNNClassifier(    #推定器\n",
        "        layer_list=layer_list, \n",
        "        epoch=epoch,\n",
        "        batch_size=batch_size, \n",
        "        early_stop=early_stop,\n",
        "        random_state=0, verbose = verbose)\n",
        "\n",
        "clf._init_variables(x)  # 各レイヤのインスタンス化等\n",
        "clf.layer[0].W = np.concatenate([w_x, w_h], axis=0)   # 重み\n",
        "clf.layer[0].B = b  # バイアス\n",
        "\n",
        "h = clf._exec_forward_propagation(x)  # 順伝播処理実行\n",
        "print(h)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd6TQ_eNXG9Q"
      },
      "source": [
        "## 【問題3】（アドバンス課題）バックプロパゲーションの実装\n",
        "バックプロパゲーションを実装してください。\n",
        "\n",
        "\n",
        "RNNの内部は全結合層を組み合わせた形になっているので、更新式は全結合層などと同様です。\n",
        "\n",
        "$$\n",
        "W_x^{\\prime} = W_x - \\alpha \\frac{\\partial L}{\\partial W_x} \\\\\n",
        "W_h^{\\prime} = W_h - \\alpha \\frac{\\partial L}{\\partial W_h} \\\\\n",
        "B^{\\prime} = B - \\alpha \\frac{\\partial L}{\\partial B}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8a_Fu5MXMha"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}