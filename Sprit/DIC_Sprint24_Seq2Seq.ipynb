{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIC_Sprint24_Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGTiOfkYTkrb"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rJzEOq68bice"
      },
      "source": [
        "## 【事前準備】"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIbU_lsybicl",
        "outputId": "c50af46d-a01a-4f02-8fb2-1fcd99bd11f1"
      },
      "source": [
        "# scikit-learnの「set_config(display=\"diagram\")」を使用するため、scikitlearnを最新verに更新\n",
        "# !pip install scikit-learn==0.23.2 --target drive/My\\ Drive/MyModule\n",
        "# !pip install scikit-learn==0.23.2\n",
        "# !pip install h5py==2.10\n",
        "# !pip install keras==2.2.4\n",
        "# !pip install keras-applications==1.0.7\n",
        "# !pip install tensorflow==1.14\n",
        "# !pip install -q -U albumentations   # データ拡張用ライブラリ\n",
        "!pip list\n",
        "## Google Drive上にインストールしたモジュールのインポート##\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/MyModule')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.1.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   1.12.3\n",
            "argon2-cffi                   21.1.0\n",
            "arviz                         0.11.2\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.2.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.6\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.2\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.5.30\n",
            "cffi                          1.14.6\n",
            "cftime                        1.5.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.4\n",
            "clang                         5.0\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorcet                      2.0.6\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda101                  9.1.0\n",
            "cvxopt                        1.2.6\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.10.0\n",
            "cymem                         2.0.5\n",
            "Cython                        0.29.24\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.4\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.278\n",
            "easydict                      1.9\n",
            "ecos                          2.0.7.post1\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.0.0.2\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.6\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.0.12\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.4.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.34.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.5\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.53.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.1\n",
            "grpcio                        1.39.0\n",
            "gspread                       3.0.1\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.1.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.5\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.2.0\n",
            "imbalanced-learn              0.4.3\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.6.4\n",
            "importlib-resources           5.2.2\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2021.3.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.3\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.19\n",
            "jaxlib                        0.1.70+cuda110\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.0\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.0.1\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    2.6.0\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.7.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.5\n",
            "keras                         2.6.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.1\n",
            "korean-lunar-calendar         0.2.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.4\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-inline             0.1.2\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.8.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.2\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.9\n",
            "murmurhash                    1.0.5\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.4\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.1\n",
            "netCDF4                       1.5.7\n",
            "networkx                      2.6.2\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.7.3\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.4.3\n",
            "panel                         0.12.1\n",
            "param                         1.11.1\n",
            "parso                         0.8.2\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.1\n",
            "pep517                        0.11.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.4.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.5\n",
            "prettytable                   2.1.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.11.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "protobuf                      3.17.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.10.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.2\n",
            "pycparser                     2.20\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.2.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.2\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  2.5.6\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.1.1\n",
            "PyYAML                        3.13\n",
            "pyzmq                         22.2.1\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.1.1\n",
            "QtPy                          1.10.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.23.0\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.7.2\n",
            "scikit-image                  0.16.2\n",
            "scikit-learn                  0.22.2.post1\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           2.1.4\n",
            "seaborn                       0.11.1\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.7.1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.1.0\n",
            "snowballstemmer               2.1.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.5\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.22\n",
            "sqlparse                      0.4.1\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.6.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.6.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.6.0\n",
            "tensorflow-gcs-config         2.6.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-metadata           1.2.0\n",
            "tensorflow-probability        0.13.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.11.0\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "tifffile                      2021.8.30\n",
            "toml                          0.10.2\n",
            "tomli                         1.2.1\n",
            "toolz                         0.11.1\n",
            "torch                         1.9.0+cu102\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu102\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.0\n",
            "traitlets                     5.0.5\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.7.4.3\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.8.2\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.0\n",
            "widgetsnbextension            3.5.1\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.12.1\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   0.9.1\n",
            "zict                          2.0.0\n",
            "zipp                          3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_mFqIdjbico",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d79be99-140d-41df-b0a6-26c632e43b4c"
      },
      "source": [
        "## モジュールのインポート ##\n",
        "# 一般\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "import math\n",
        "import collections\n",
        "# データ分析\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import make_blobs\n",
        "# 決定木可視化のためのツール\n",
        "import graphviz\n",
        "import pydotplus\n",
        "# from IPython.display import Image\n",
        "# from sklearn.externals.six import StringIO\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "# Keras\n",
        "# from keras.datasets import mnist\n",
        "# SciPy\n",
        "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix, lil_matrix\n",
        "# 画像データ編集\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "# 自然言語処理\n",
        "from gensim.models import Word2Vec\n",
        "# その他\n",
        "from google.colab import drive #GoogleDriveモジュール\n",
        "drive.mount('/content/drive') #GoogleDriveのマウント\n",
        "# os.chdir('/content/drive/My Drive/DIVE INTO CODE/Sprint/Sprint24')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq1LuDCTuji0"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/DIVE INTO CODE/Sprint/Sprint24')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P5ccCTPTovY"
      },
      "source": [
        "## 【問題1】機械翻訳の実行とコードリーディング\n",
        "以下のサンプルコードは、短い英語からフランス語への変換を行うものです。これを動かしてください。\n",
        "\n",
        "\n",
        "keras/lstm_seq2seq.py at master · rstudio/keras\n",
        "\n",
        "\n",
        "その上でこのサンプルコードの各部分がどういった役割かを読み取り、まとめてください。以下のようにどこからどこの行が何をしているかを記述してください。\n",
        "\n",
        "\n",
        "（例）\n",
        "\n",
        "\n",
        "51から55行目 : ライブラリのimport\n",
        "57から62行目 : ハイパーパラメータの設定\n",
        "\n",
        "《文字単位のトークン化》\n",
        "\n",
        "\n",
        "この実装ではテキストのベクトル化の際に、単語ではなく文字ごとを1つのトークンとして扱っています。\n",
        "\n",
        "\n",
        "scikit-learnでBoWを計算するCountVectorizerの場合では、デフォルトの引数はanalyzer=’word’で単語を扱いますが、charやchar_wbとすることで文字を扱えるようになります。\n",
        "\n",
        "\n",
        "charとchar_wbの2種類の方法があり、char_wbを指定した場合、n_gramが単語内からのみ作成されます。逆にcharは単語の区切りが関係なくn_gramが作成されます。This movie is very good.というテキストを3-gramでカウントする時、charではs mやe iといった単語をまたぐ数え方もしますが、char_wbではこれらを見ません。\n",
        "\n",
        "\n",
        "sklearn.feature_extraction.text.CountVectorizer — scikit-learn 0.21.3 documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo3LrC6sTfNV",
        "outputId": "ce4bdf46-25b4-4d26-e3b5-c91d2afd7bb0"
      },
      "source": [
        "'''Sequence to sequence example in Keras (character-level).\n",
        "\n",
        "This script demonstrates how to implement a basic character-level\n",
        "sequence-to-sequence model. We apply it to translating\n",
        "short English sentences into short French sentences,\n",
        "character-by-character. Note that it is fairly unusual to\n",
        "do character-level machine translation, as word-level\n",
        "models are more common in this domain.\n",
        "\n",
        "# Summary of the algorithm:\n",
        "\n",
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and correspding target sequences from another domain\n",
        "    (e.g. French sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    Is uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit.\n",
        "\n",
        "# Data download:\n",
        "\n",
        "English to French sentence pairs.\n",
        "https://www.manythings.org/anki/fra-eng.zip\n",
        "\n",
        "Lots of neat sentence pairs datasets can be found at:\n",
        "https://www.manythings.org/anki/\n",
        "\n",
        "# References:\n",
        "\n",
        "- Sequence to Sequence Learning with Neural Networks\n",
        "    https://arxiv.org/abs/1409.3215\n",
        "- Learning Phrase Representations using\n",
        "    RNN Encoder-Decoder for Statistical Machine Translation\n",
        "    https://arxiv.org/abs/1406.1078\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = 'fra-eng/fra.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "lines = open(data_path).read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    a = line.split('\\t')\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s.h5')\n",
        "\n",
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])    # 出力の最後のシーケンスデータ（文字）のインデックス番号を取得\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]   # インデックス番号から文字に変換\n",
        "        decoded_sentence += sampled_char  # 得られた文字をdecoded_sentenceに格納\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        # 終端文字か最大シーケンス長に達した場合はstop_conditionをTrueに設定\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))   # ターゲットシーケンスの格納用変数を0クリア\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training test)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 59\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 8s 18ms/step - loss: 0.9768 - val_loss: 1.0730\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.9115 - val_loss: 1.0308\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.8636 - val_loss: 0.9619\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.8252 - val_loss: 0.9385\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7933 - val_loss: 0.9313\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7664 - val_loss: 0.8614\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7445 - val_loss: 0.8388\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7240 - val_loss: 0.8178\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7062 - val_loss: 0.8486\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6910 - val_loss: 0.7877\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6762 - val_loss: 0.7495\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6632 - val_loss: 0.7815\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6528 - val_loss: 0.7359\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6432 - val_loss: 0.7311\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6327 - val_loss: 0.7063\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6253 - val_loss: 0.7072\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6184 - val_loss: 0.7277\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6112 - val_loss: 0.7312\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6053 - val_loss: 0.7089\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5989 - val_loss: 0.7097\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5939 - val_loss: 0.7348\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5897 - val_loss: 0.7013\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.5850 - val_loss: 0.7125\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5806 - val_loss: 0.6836\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5758 - val_loss: 0.7092\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5734 - val_loss: 0.6918\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5684 - val_loss: 0.7153\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5631 - val_loss: 0.7018\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5606 - val_loss: 0.6747\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5569 - val_loss: 0.6730\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5519 - val_loss: 0.6777\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5484 - val_loss: 0.6836\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5440 - val_loss: 0.6654\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5398 - val_loss: 0.6524\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5359 - val_loss: 0.6857\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5318 - val_loss: 0.6702\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5287 - val_loss: 0.6770\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5241 - val_loss: 0.6527\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5188 - val_loss: 0.6830\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5158 - val_loss: 0.6610\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5103 - val_loss: 0.6410\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5068 - val_loss: 0.6531\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5036 - val_loss: 0.6483\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5009 - val_loss: 0.6448\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4973 - val_loss: 0.6301\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4935 - val_loss: 0.6490\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4910 - val_loss: 0.6315\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4876 - val_loss: 0.6550\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4850 - val_loss: 0.6495\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4826 - val_loss: 0.6370\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4794 - val_loss: 0.6352\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4775 - val_loss: 0.6265\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4738 - val_loss: 0.6317\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4719 - val_loss: 0.6203\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4681 - val_loss: 0.6250\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4667 - val_loss: 0.6210\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4643 - val_loss: 0.6393\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4623 - val_loss: 0.6324\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4597 - val_loss: 0.6273\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4583 - val_loss: 0.6066\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4550 - val_loss: 0.6159\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4515 - val_loss: 0.6086\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4488 - val_loss: 0.6177\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4476 - val_loss: 0.6074\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4440 - val_loss: 0.6125\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4427 - val_loss: 0.6150\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4402 - val_loss: 0.6130\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4403 - val_loss: 0.6128\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4373 - val_loss: 0.6074\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4361 - val_loss: 0.6084\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4338 - val_loss: 0.5906\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4323 - val_loss: 0.6163\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4311 - val_loss: 0.6075\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4281 - val_loss: 0.6101\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4270 - val_loss: 0.6006\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4271 - val_loss: 0.6072\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4236 - val_loss: 0.6416\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4243 - val_loss: 0.6075\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4213 - val_loss: 0.5942\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4200 - val_loss: 0.6002\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4180 - val_loss: 0.5963\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4181 - val_loss: 0.6037\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4154 - val_loss: 0.6041\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4133 - val_loss: 0.5998\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4118 - val_loss: 0.6003\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4105 - val_loss: 0.5876\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4094 - val_loss: 0.6158\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4079 - val_loss: 0.5970\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4082 - val_loss: 0.6016\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4059 - val_loss: 0.6222\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4052 - val_loss: 0.6011\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4029 - val_loss: 0.5938\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4016 - val_loss: 0.6056\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4026 - val_loss: 0.5941\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4001 - val_loss: 0.5939\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3983 - val_loss: 0.6091\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.3973 - val_loss: 0.5988\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3954 - val_loss: 0.5894\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3942 - val_loss: 0.5941\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3933 - val_loss: 0.5878\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Courr.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Courr.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Courr.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Cales-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Cales-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File .\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: C'ais ta te.\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Qus a mons ait .\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Laissez-vous .\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Laissez-vous .\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Laissez-vous .\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Suis e  eeeee .\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Sous de cous.\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Calmez-vous.\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Calmez-vous.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Soure.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Soure.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrêtez-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrêtez-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrêtez-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attende.\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commence.\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commence.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Sour de.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Sour de.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je mon aite.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je mon aite.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Je sait.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je l'ai en train de marder.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je l'ai en train de marder.\n",
            "\n",
            "-\n",
            "Input sentence: I won.\n",
            "Decoded sentence: J'ai pron de te toi.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Finez le tous.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Sourie .\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Sourie .\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Sourie .\n",
            "\n",
            "-\n",
            "Input sentence: Sorry?\n",
            "Decoded sentence: Laisse parter.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Fais sout coures.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Fais sout coures.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Fais sout coures.\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Sarti.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Sarti.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Sarti.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Sarti.\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Décampe.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Décampe.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Décampe.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va tous plas .\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va tous plas .\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Va tous plas .\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Commis.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Commis.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Commis.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Commiis.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Commiis.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Commiis.\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Monte.\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Monte.\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Serre-moi la bien.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOUAKjRZl-2S",
        "outputId": "78e6c529-aed6-417d-b0da-9b9b34284ecf"
      },
      "source": [
        "print(input_texts[:10])\n",
        "print(input_characters)\n",
        "print(encoder_input_data[:2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go.', 'Go.', 'Go.', 'Hi.', 'Hi.', 'Run!', 'Run!', 'Run!', 'Run!', 'Run!']\n",
            "[' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é']\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cvPBop3m3fL",
        "outputId": "2fcb87d0-1ea3-4f22-eca4-37632f606bcd"
      },
      "source": [
        "print(target_texts[:10])\n",
        "print(target_characters)\n",
        "print(decoder_input_data[:2])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\tVa !\\n', '\\tMarche.\\n', '\\tBouge !\\n', '\\tSalut !\\n', '\\tSalut.\\n', '\\tCours\\u202f!\\n', '\\tCourez\\u202f!\\n', '\\tPrenez vos jambes à vos cous !\\n', '\\tFile !\\n', '\\tFilez !\\n']\n",
            "['\\t', '\\n', ' ', '!', '%', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '’', '\\u202f']\n",
            "[[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DDcwWtHCrv"
      },
      "source": [
        "### 【問題1 解答】\n",
        "一部正しくフランス語に翻訳されていない単語もあるが、おおむね期待通りの翻訳がされることを確認できた。\n",
        "\n",
        "また、コードリーディングした結果、ソースコードの内容は主に以下の処理フローになっていることを確認できた。\n",
        "\n",
        "- 69行目～： fra.txtをオープン\n",
        "- 70～83行目： txtファイルの先頭行から順番に読み出してタブで分割し、各行の先頭の文字列（入力テキスト／英語）と2番目の文字列（ターゲットテキスト／フランス語）で使用されている文字のセット（集合）を作成\n",
        "- 85～86行目： 上記で作成した使用文字のセットを昇順にソート\n",
        "- 87～88行目： 使用文字のセットの長さから、エンコーダとデコーダのトークン数を設定\n",
        "- 89～90行目： 入力テキストとターゲットテキストの各々の最大長から、エンコーダとデコーダのシーケンス長を設定\n",
        "- 92～96行目： サンプル数、エンコーダやデコーダのトークン数および最大シーケンス長を標準出力\n",
        "- 98～101行目： 各トークンのインデックスの辞書を作成\n",
        "- 103～111行目： 下記の各データを格納するためのndarrayを初期化（0パディング）\n",
        " - エンコーダの入力データ / shape:(サンプル数, エンコーダの最大シーケンス長, エンコーダのトークン数)\n",
        " - デコーダの入力データ / shape:(サンプル数, デコーダの最大シーケンス長, デコーダのトークン数)\n",
        " - デコーダの出力データ / shape:(サンプル数, デコーダの最大シーケンス長, デコーダのトークン数)\n",
        "- 113～122行目： 上記で作成した使用文字のセットを使用して、入力テキストとターゲットテキストの各テキスト文字をユニークな数値に置換（インデックス化）\n",
        "- 125～144行目： 1層のLSTMで構成されるエンコーダと、1層ずつのLSTMとDenseで構成されるデコーダを学習モデルとして作成（エンコーダのLSTMの出力値である短期記憶(state_h)と長期記憶(state_c)がデコーダのLSTMに入力されるように接続する）\n",
        "- 147行目： モデルをコンパイル\n",
        "- 148～151行目： 上記で各文字をインデックス化した入力テキストとターゲットテキストを用いて学習\n",
        "- 153行目： パラメータを.h5ファイルに保存\n",
        "- 164行目： 推定に使用するエンコーダモデルを作成（学習モデルのLSTMのインスタンスを流用）\n",
        "- 165～175行目： 推定に使用するデコーダモデルを作成（学習モデルのLSTMやDenseのインスタンスを流用）\n",
        "- 179～182行目： 文字とインデックス番号の対応表の辞書のkeyとvalueを入れ替える（インデックス番号から文字の種類を検索できるようにする）\n",
        "- 185～219行目： シーケンスのデコード処理の関数定義\n",
        " - 入力テキストをエンコーダモデルに入力し、states_valueを取得\n",
        " - states_valueとターゲットテキストの開始文字を表す「'\\t'」（をインデックス化したもの）をデコーダに入力\n",
        " - デコーダが推定した文字をdecoded_sentenceに格納。以降、推定した文字と隠れ状態をデコーダに再帰的に入力して続きの文字を推定する。これを、終端文字か最大テキスト長にたどり着くまで続ける。\n",
        "- 224～231行目： 入力テキストデータ（各英単語）を上記のデコード用関数に１つずつ順番に入力していきデコード（フランス語への変換）を行う。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F50MfRYm0JSV"
      },
      "source": [
        "他の活用例としてイメージキャプショニングがあります。画像に対する説明の文章を推定するタスクです。これは画像を入力し、系列データを出力する Image to Sequence の手法によって行えます。\n",
        "\n",
        "\n",
        "pytorch-tutorial/tutorials/03-advanced/image_captioning at master · yunjey/pytorch-tutorial\n",
        "\n",
        "\n",
        "イメージキャプショニングは学習に多くの時間がかかるため、ここでは学習済みの重みが公開されている実装を動かすことにします。Kerasには平易に扱える実装が公開されていないため、今回はPyTorchによる実装を扱います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kpCqMfk0NAj"
      },
      "source": [
        "## 【問題2】イメージキャプショニングの学習済みモデルの実行\n",
        "上記実装において 5. Test the model の項目を実行してください。また、自身で用意した画像に対しても文章を生成してください。これらに対してどういった文章が出力されたかを記録して提出してください。\n",
        "\n",
        "\n",
        "データセットからの学習は行わず、学習済みの重みをダウンロードして利用します。\n",
        "\n",
        "\n",
        "注意点として、デフォルトで設定されている重みのファイル名と、ダウンロードできる重みのファイル名は異なっています。ここは書き換える必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlCCtQisXpmV",
        "outputId": "0a3e2d35-c43b-4ce5-d034-aadf4d28ff8c"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/DIVE INTO CODE/Sprint/Sprint24/pytorch-tutorial/tutorials/03-advanced/image_captioning/')\n",
        "!python sample.py --image='png/example.png'\n",
        "# !python \"/content/drive/My Drive/DIVE INTO CODE/Sprint/Sprint24/pytorch-tutorial/tutorials/03-advanced/image_captioning/sample.py\" --image='png/example.png'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100% 230M/230M [00:02<00:00, 84.8MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "<start> a group of giraffes standing next to each other . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NvfAwyr6QVL",
        "outputId": "625ae814-c17e-47cb-e66c-0023cb8b970c"
      },
      "source": [
        "!python sample.py --image=\"png/P_20191124_110036.jpg\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "<start> a group of people standing on a sidewalk next to a tree . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9st3pLyhdZx"
      },
      "source": [
        "### 【問題2 解答】\n",
        "\n",
        "それぞれの画像データに対し、下記のようにキャプションされた。\n",
        "- example.png\n",
        "\n",
        "「a group of giraffes standing next to each other」（隣同士に立っているキリンのグループ）\n",
        "\n",
        "- P_20191124_110036.jpg\n",
        "\n",
        "「a group of people standing on a sidewalk next to a tree」\n",
        "（木の隣の歩道に立っている人々のグループ）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMpf85E60PSs"
      },
      "source": [
        "## 【問題3】Kerasで動かしたい場合はどうするかを調査\n",
        "PyTorchによる実装を動かしましたが、何らかの理由からKerasで動かしたい状況が考えられます。どういった手順を踏むことになるか調査し、できるだけ詳しく説明してください。\n",
        "\n",
        "\n",
        "特に今回はPyTorchのための学習済みの重みをKerasで使えるようにしたいので、その点については必ず触れてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "267HycKw83Xs"
      },
      "source": [
        "### 【問題3 解答】\n",
        "PyTorchからKerasに変更する際には、主に下記の箇所の修正が必要。\n",
        "\n",
        "- model.py\n",
        " - モデル定義に使用されているPyTorchの各レイヤのクラスをKerasのものに変更\n",
        "- sample.py\n",
        " - 使用するデバイスの指定方法（torch.device ⇒ tf.config.experimental.set_virtual_device_configuration等に変更する）\n",
        " - 学習済みパラメータのロード処理を、Pytorch（load_state_dictメソッド）からKerasのものに変更する\n",
        "- 学習済みパラメータファイル（decoder-5-3000.pklなど）\n",
        "\n",
        " - Kerasでは学習済みパラメータは.h5ファイルに保存されるので、pickleモジュールを用いて.pklファイルを読み出し、フォーマットを.h5用に変換した上でh5pyモジュールを用いて.h5ファイルに保存する必要がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS1c52NK0Rlq"
      },
      "source": [
        "## 【問題4】（アドバンス課題）コードリーディングと書き換え\n",
        "モデル部分はmodel.pyに書かれていますが、Kerasではこのモデルがどのように記述できるかを考え、コーディングしてください。その際機械翻訳のサンプルコードが参考になります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdh-lp_X0VQQ"
      },
      "source": [
        "## 【問題5】（アドバンス課題）発展的調査\n",
        "《他の言語の翻訳を行う場合は？》\n",
        "\n",
        "\n",
        "問題1の実装を使い日本語と英語の翻訳を行いたい場合はどのような手順を踏むか考えてみましょう。\n",
        "\n",
        "\n",
        "《機械翻訳の発展的手法にはどのようなものがある？》\n",
        "\n",
        "\n",
        "機械翻訳のための発展的手法にはどういったものがあるか調査してみましょう。\n",
        "\n",
        "\n",
        "《文章から画像生成するには？》\n",
        "\n",
        "\n",
        "イメージキャプショニングとは逆に文章から画像を生成する手法もあります。どういったものがあるか調査してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_fbiM5O0Jzq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}